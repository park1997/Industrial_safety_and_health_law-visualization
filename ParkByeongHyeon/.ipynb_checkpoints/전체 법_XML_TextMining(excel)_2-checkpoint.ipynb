{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "# key => \n",
    "# 산업안전보건법 + \"1\"\n",
    "# 건설기술진흥법 + \"2\"\n",
    "# 위험물안전관리법 + '3'\n",
    "# 전기안전관리법 + \"4\"\n",
    "# 화학물질관리법 + \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industrial = pd.read_excel(\"산업안전보건법.xlsx\")\n",
    "df_erection = pd.read_excel(\"건설기술진흥법.xlsx\")\n",
    "df_danger = pd.read_excel(\"위험물안전관리법.xlsx\")\n",
    "df_electric = pd.read_excel(\"전기안전관리법.xlsx\")\n",
    "df_chemistry = pd.read_excel(\"화학물질관리법.xlsx\")\n",
    "df_info = pd.DataFrame()\n",
    "df_info = df_info.append(df_industrial,ignore_index = True)\n",
    "df_info = df_info.append(df_erection,ignore_index = True)\n",
    "df_info = df_info.append(df_danger,ignore_index = True)\n",
    "df_info = df_info.append(df_electric,ignore_index = True)\n",
    "df_info = df_info.append(df_chemistry,ignore_index = True)\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_info.to_excel('전체법.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트\n",
    "# 불용어, 불필요 단어 제거\n",
    "stop_words_df = pd.read_excel(\"stopwords.xlsx\")\n",
    "stop_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = df_info.get(\"조내용\")\n",
    "posts_key = df_info.get(\"키\")\n",
    "key = [i for i in posts_key]\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(**key) :\n",
    "    dic = {}\n",
    "    for k, y in key.items():\n",
    "        if k[-1] == \"1\" :\n",
    "            s = \"OSH\"+k[0:(len(k)-4)]\n",
    "        elif k[-1]==\"2\":\n",
    "            s = \"CTP\"+k[0:(len(k)-4)]\n",
    "        elif k[-1]==\"3\":\n",
    "            s = \"HSM\"+k[0:(len(k)-4)]\n",
    "        elif k[-1]==\"4\":\n",
    "            s = \"ESM\"+k[0:(len(k)-4)]\n",
    "        elif k[-1]==\"5\":\n",
    "            s = \"CMM\"+k[0:(len(k)-4)]     \n",
    "        if k[-3] != \"0\":\n",
    "            s += \"의 \"+k[-3]   \n",
    "        dic[s] = y\n",
    "    return dic   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_law(law):\n",
    "    if law == 'OSH':\n",
    "        num = '1'\n",
    "    elif law == 'CTP':\n",
    "        num = '2'\n",
    "    elif law == 'HSM':\n",
    "        num = '3'\n",
    "    elif law == 'ESM':\n",
    "        num = '4'\n",
    "    elif law == 'CMM':\n",
    "        num = '5'\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "oo = okt.pos(posts[0],\n",
    "        norm=True,   # 정규화(normalization)\n",
    "        stem=True    # 어간추출(stemming)\n",
    "        )\n",
    "print(oo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_1(raw_texts, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=list(stop_words_df.get(\"불용어\"))):\n",
    "    p = okt.pos(raw_texts, \n",
    "            norm=True,   # 정규화(normalization)\n",
    "            stem=True    # 어간추출(stemming)\n",
    "            )\n",
    "    o = [word for word, tag in p if len(word) > 1 and tag in pos and word[0] not in stopword]\n",
    "    return(o)\n",
    "\n",
    "tokenizer_1(posts[80])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tagger = Mecab()\n",
    "# from eunjeon import Mecab\n",
    "# tagger = Mecab()\n",
    "def tokenizer_2(raw_texts, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stop_words=list(stop_words_df.get(\"불용어\"))):\n",
    "    nouns = []\n",
    "  \n",
    "    for noun in tagger.nouns(raw_texts):\n",
    "        if noun not in stop_words:\n",
    "            nouns.append(noun)\n",
    "    return nouns\n",
    "\n",
    "tokenizer_2(posts[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer_1, # 문장에 대한 tokenizer (위에 정의한 함수 이용)\n",
    "    min_df=1,            # 단어가 출현하는 최소 문서의 개수\n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")\n",
    "\n",
    "X = vectorize.fit_transform(posts)\n",
    "X.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 euclidean distance 를 계산\n",
    "euclidean_result = []\n",
    "for x in range(len(df_info)):\n",
    "    tmp = []\n",
    "    for y in range(len(df_info)):\n",
    "        tmp.append(euclidean_distances(X[x], X[y])[0][0])\n",
    "    euclidean_result.append(tmp)\n",
    "# euclidean_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 euclidean distance 결과 값을\n",
    "# DataFrame 형태로 변환\n",
    "euclidean_result_df = pd.DataFrame(euclidean_result)\n",
    "euclidean_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "law_jo = 'OSH24'\n",
    "        \n",
    "if law_jo[-3] == '의':\n",
    "    if len(law_jo) == 7 :\n",
    "        jo_key = law_jo[3] + '0' + law_jo[-1] + '1'+ get_law(law_jo[0:3])\n",
    "    elif len(law_jo) == 8 :\n",
    "        jo_key = law_jo[3:5] + '0' + law_jo[-1] + '1'+ get_law(law_jo[0:3])\n",
    "    elif len(law_jo) == 9 :\n",
    "        jo_key = law_jo[3:6] + '0' + law_jo[-1] + '1'+ get_law(law_jo[0:3])\n",
    "else:    \n",
    "    jo_key = law_jo[3:] + '001' + get_law(law_jo[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance 값으로 \n",
    "# 8조와 가장 비슷한 조를 찾기위한 과정\n",
    "# jo_key = 240011\n",
    "jo = key.index(int(jo_key))\n",
    "y_euclidean = euclidean_result_df[jo]\n",
    "dic = {}\n",
    "for i in range(len(y_euclidean)):\n",
    "    dic[str(posts_key[i])] = y_euclidean[i] \n",
    "dic = get_key(**dic)\n",
    "#8조와 비슷한 조 찾기 위함\n",
    "# euclidean distance 를 dic에 씌워 sorting 함(1부터 10위까지)\n",
    "sorted(dic.items(), key=lambda x: x[1])[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_result = []\n",
    "for x in range(len(df_info)):\n",
    "    tmp = []\n",
    "    for y in range(len(df_info)):\n",
    "        tmp.append(cosine_similarity(X[x], X[y])[0][0])\n",
    "    cosine_result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 cosine similarity 결과 값을\n",
    "# DataFrame 형태로 변환\n",
    "cosine_result_df = pd.DataFrame(cosine_result)\n",
    "cosine_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity 값으로 \n",
    "# 8조와 가장 비슷한 조를 찾기위한 과정\n",
    "y_cosine = cosine_result_df[jo]\n",
    "dic ={}\n",
    "for i in range(len(y_cosine)):\n",
    "    dic[str(posts_key[i])] = y_cosine[i]\n",
    "dic = get_key(**dic)\n",
    "#8조와 비슷한 조 찾기 위함\n",
    "# euclidean distance 를 dic에 씌워 sorting 함(1부터 10위까지)\n",
    "sorted(dic.items(), key=lambda x: x[1], reverse = True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "# 워크북 열기\n",
    "wb = openpyxl.load_workbook('TF-IDF결과.xlsx')\n",
    "# 시트 열기(활성화)\n",
    "sheet = wb['안전보건법령 간']\n",
    "\n",
    "# 제시된 틀 만들기\n",
    "sheet['A1'] = '안전보건법령 간 TF-IDF 기준'\n",
    "for i in range(10) :\n",
    "    sheet.cell(row=2, column=i+2).value = i+1\n",
    "for i in range(0,141) :\n",
    "    s = \"OSH\"+str(i+1)\n",
    "    sheet.cell(row=i+3, column=1).value = s\n",
    "\n",
    "# 상위 유사조항 10개   \n",
    "for j in range(0,141) :\n",
    "    y_cosine = cosine_result_df[j]\n",
    "    dic ={}\n",
    "    for i in range(len(y_cosine)):\n",
    "        dic[str(posts_key[i])] = y_cosine[i]\n",
    "    dic = get_key(**dic)\n",
    "    a = sorted(dic.items(), key=lambda x: x[1], reverse = True)[1:11]\n",
    "    for i in range(10) :\n",
    "        sheet.cell(row=j+3, column=i+2).value = str(a[i][0])\n",
    "\n",
    "# 저장\n",
    "wb.save('TF-IDF결과.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countv = CountVectorizer(stop_words = list(stop_words_df.get(\"불용어\")))\n",
    "sp_mat = countv.fit_transform(posts)\n",
    "# 희소행렬을 np array로\n",
    "sp_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = CountVectorizer(\n",
    "    tokenizer=tokenizer_2, # 문장에 대한 tokenizer (위에 정의한 함수 이용)\n",
    "    min_df=1,            # 단어가 출현하는 최소 문서의 개수\n",
    ")\n",
    "\n",
    "X = vectorize.fit_transform(posts)\n",
    "X.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 euclidean distance 를 계산\n",
    "euclidean_result = []\n",
    "for x in range(len(df_info)):\n",
    "    tmp = []\n",
    "    for y in range(len(df_info)):\n",
    "        tmp.append(euclidean_distances(X[x], X[y])[0][0])\n",
    "    euclidean_result.append(tmp)\n",
    "# euclidean_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 euclidean distance 결과 값을\n",
    "# DataFrame 형태로 변환\n",
    "euclidean_result_df = pd.DataFrame(euclidean_result)\n",
    "euclidean_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance 값으로 \n",
    "# 8조와 가장 비슷한 조를 찾기위한 과정\n",
    "y_euclidean = euclidean_result_df[jo]\n",
    "dic = {}\n",
    "for i in range(len(y_euclidean)):\n",
    "    dic[str(posts_key[i])] = y_euclidean[i]\n",
    "dic = get_key(**dic)\n",
    "#8조와 비슷한 조 찾기 위함\n",
    "# euclidean distance 를 dic에 씌워 sorting 함(1부터 10위까지)\n",
    "sorted(dic.items(), key=lambda x: x[1])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "# 워크북 열기\n",
    "wb = openpyxl.load_workbook('count결과(Eu).xlsx')\n",
    "# 시트 열기(활성화)\n",
    "sheet = wb['안전보건법령 간']\n",
    "\n",
    "# 제시된 틀 만들기\n",
    "sheet['A1'] = '안전보건법령 간 count결과(Eu) 기준'\n",
    "for i in range(10) :\n",
    "    sheet.cell(row=2, column=i+2).value = i+1\n",
    "for i in range(0,141) :\n",
    "    s = \"OSH\"+str(i+1)\n",
    "    sheet.cell(row=i+3, column=1).value = s\n",
    "\n",
    "# 상위 유사조항 10개   \n",
    "for j in range(0,141) :\n",
    "    y_euclidean = euclidean_result_df[j]\n",
    "    dic ={}\n",
    "    for i in range(len(y_euclidean)):\n",
    "        dic[str(posts_key[i])] = y_euclidean[i]\n",
    "    dic = get_key(**dic)\n",
    "    a = sorted(dic.items(), key=lambda x: x[1])[1:11]\n",
    "    for i in range(10) :\n",
    "        sheet.cell(row=j+3, column=i+2).value = str(a[i][0])\n",
    "\n",
    "# 저장\n",
    "wb.save('count결과(Eu).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_result = []\n",
    "for x in range(len(df_info)):\n",
    "    tmp = []\n",
    "    for y in range(len(df_info)):\n",
    "        tmp.append(cosine_similarity(X[x], X[y])[0][0])\n",
    "    cosine_result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 조에 해당하는 cosine similarity 결과 값을\n",
    "# DataFrame 형태로 변환\n",
    "cosine_result_df = pd.DataFrame(cosine_result)\n",
    "cosine_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity 값으로 \n",
    "# 8조와 가장 비슷한 조를 찾기위한 과정\n",
    "y_cosine = cosine_result_df[jo]\n",
    "dic ={}\n",
    "for i in range(len(y_cosine)):\n",
    "    dic[str(posts_key[i])] = y_cosine[i]\n",
    "dic = get_key(**dic)\n",
    "#8조와 비슷한 조 찾기 위함\n",
    "# euclidean distance 를 dic에 씌워 sorting 함(1부터 10위까지)\n",
    "sorted(dic.items(), key=lambda x: x[1], reverse = True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "# 워크북 열기\n",
    "wb = openpyxl.load_workbook('count결과(C).xlsx')\n",
    "# 시트 열기(활성화)\n",
    "sheet = wb['안전보건법령 간']\n",
    "\n",
    "# 제시된 틀 만들기\n",
    "sheet['A1'] = '안전보건법령 간 count결과(C) 기준'\n",
    "for i in range(10) :\n",
    "    sheet.cell(row=2, column=i+2).value = i+1\n",
    "for i in range(0,141) :\n",
    "    s = \"OSH\"+str(i+1)\n",
    "    sheet.cell(row=i+3, column=1).value = s\n",
    "\n",
    "# 상위 유사조항 10개   \n",
    "for j in range(0,141) :\n",
    "    y_cosine = cosine_result_df[j]\n",
    "    dic ={}\n",
    "    for i in range(len(y_cosine)):\n",
    "        dic[str(posts_key[i])] = y_cosine[i]\n",
    "    dic = get_key(**dic)\n",
    "    a = sorted(dic.items(), key=lambda x: x[1], reverse = True)[1:11]\n",
    "    for i in range(10) :\n",
    "        sheet.cell(row=j+3, column=i+2).value = str(a[i][0])\n",
    "\n",
    "# 저장\n",
    "wb.save('count결과(C).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
